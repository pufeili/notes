# 数据预处理之标准化正则化归一化

## 1 归一化

经常听到的有 L2范数归一化（L2 normalization） 、零均值归一化（zero-mean normalization）、 尺度归一化。

L2归一化 针对的是每个样本自己的特征，尺度归一化 针对的是整个数据集的特征，即x1和x2对应的每一个维度的特征，后面有举例说明。

### 1.1  L2归一化

其中 **L2 归一化**是将每个样本向量的 L2 范数归一化为 1。这种归一化通常用于向量相似性度量，因为在 L2 空间中，向量之间的距离可以用余弦相似度来度量。这个归一化为1的意思是将每个样本向量的L2范数（欧几里得范数）归一化为1，而不是将每个特征值的范围归一化到1。
$$
x_{i}^{\prime}= \frac{x_{i}}{norm(x)}
$$

$$
1=norm(x^{\prime})= \frac{\sqrt{x_{1}^{2}+x_{2}^{2}+ \ldots +x_{n}^{2}}}{norm(x)}
$$

具体来说，对于一个m行n列的数据矩阵X，该归一化方法的目的是将每一行向量x归一化为单位向量，即 $||x||_2 = 1$，其中$ ||x||_2 $表示向量x的L2范数，计算公式为 $||x||_2 = sqrt(sum(x_i^2))$，i表示向量中的每个元素。

这种归一化方法有时也称为**L2范数归一化**或**向量归一化**。它可以在不破坏数据分布的情况下，减少数据的尺度和方差，有利于提高模型的稳定性和泛化能力。

```matlab
%  normalize each row to unit
A = A./repmat(sqrt(sum(A.^2,2)),1,size(A,2));

%  normalize each column to unit
A = A./repmat(sqrt(sum(A.^2,1)),size(A,1),1);

%  或者使用bsxfun函数
bsxfun(@times, Xs, 1./max(1e-12, sqrt(sum(Xs.^2))))

%  这两个代码的作用是相同的，但是实现方法略有不同。第一个代码使用了 bsxfun 函数，可以避免使用 repmat 函数，而第二个代码则使用了 repmat 函数来复制行向量，因此会多占用一些内存。同时，由于 bsxfun 函数自动进行广播，因此第一个代码也稍微快一些。

```

> L2范数归一化针对的是每个样本自己的特征，目的是让每个样本在特征维度上具有相同的重要性，使得在后续的机器学习任务中每个特征对预测结果的贡献度相当，避免特征之间的差异造成的偏差。
>
> 而特征值范围归一化针对的是整个数据集的特征，目的是让不同的特征在取值范围上具有相同的重要性，使得在后续的机器学习任务中每个特征对预测结果的贡献度相当，避免特征之间的尺度差异造成的影响。

### 1.2 零均值归一化

相比之下，**零均值归一化**是减去每个特征的平均值，以使每个特征的均值为 0，然后将每个特征缩放到相同的尺度。这种归一化通常用于神经网络的训练和其他机器学习任务，因为它可以加速训练和提高模型的鲁棒性。**零均值归一化** 就是在L2归一化前，进行**均值减法**。

因此，是否需要在 L2 归一化之前进行均值减法，取决于具体的应用场景和数据的特点。如果数据已经经过了零均值归一化或者不需要进行零均值归一化，那么就可以直接进行 L2 归一化。如果数据还没有进行零均值归一化，那么可以在 L2 归一化之前进行均值减法，以得到更好的归一化效果。

```matlab
meanXs = mean(Xs, 2);
Xs = bsxfun(@minus, Xs, meanXs);
Xs = bsxfun(@times, Xs, 1./max(1e-12, sqrt(sum(Xs.^2))));
```

### 1.3 尺度归一化

其实就是 0-1归一化，将整个数据的特征范围归一化到0-1。

目的：将特征值范围归一化到1的目的是将数据中不同特征的取值范围（即最大值和最小值之间的差）归一化到相同的尺度，从而避免某些特征的值过大或过小对模型的影响过大，使得各个特征在模型中的权重更加平等。

归一化方式：将特征值范围归一化到1可以采用不同的方法，例如将每个特征值除以其取值范围的最大值和最小值之差，或者将每个特征值减去其均值，然后除以其标准差。

适用范围：

将L2范数归一化为1适用于需要计算向量相似度的任务，例如聚类、分类、检索等。

将特征值范围归一化到1适用于需要训练模型的任务，例如回归、分类、神经网络等。

需要根据具体的任务和数据特点来选择合适的归一化方法，以提高模型的性能和泛化能力。

Matlab举例对比：

```matlab
%  我们假设有一个维度为2的样本矩阵X，其中有两个样本，每个样本有两个特征，即：
X = [2, 3;      4, 5];
%  对于这个样本矩阵，如果我们要进行L2范数归一化为1，那么我们需要将每个样本向量除以其L2范数，即：
X_norm = bsxfun(@rdivide, X, sqrt(sum(X.^2, 2)));

X_norm = [0.5547, 0.8321;          0.5941, 0.8047];

%  这里我们使用了bsxfun函数来实现矩阵除法，其中@rdivide表示除法运算。计算过程如下：
%  对于第一个样本[2, 3]，其L2范数为sqrt(2^2 + 3^2) = 3.6056，所以归一化后的向量为[2/3.6056, 3/3.6056] = [0.5547, 0.8321]。
%  对于第二个样本[4, 5]，其L2范数为sqrt(4^2 + 5^2) = 6.4031，所以归一化后的向量为[4/6.4031, 5/6.4031] = [0.5941, 0.8047]。

%  如果我们要进行特征值范围归一化到1，那么我们需要将每个特征值除以其取值范围的最大值和最小值之差，即：
X_range_norm = bsxfun(@rdivide, X - min(X), max(X) - min(X));

X_range_norm = [0.0, 0.0;                1.0, 1.0];

%  这里我们使用了bsxfun函数来实现矩阵减法和除法，其中@minus表示减法运算。计算过程如下：
%  对于第一个特征2，其取值范围为[2, 4]，所以归一化后的值为(2-2)/(4-2) = 0。
%  对于第二个特征3，其取值范围为[3, 5]，所以归一化后的值为(3-3)/(5-3) = 0。
%  对于第三个特征4，其取值范围为[2, 4]，所以归一化后的值为(4-2)/(4-2) = 1。
%  对于第四个特征5，其取值范围为[3, 5]，所以归一化后的值为(5-3)/(5-3) = 1。
```





### 参考：

[标准化和归一化什么区别？ - 知乎]( https://www.zhihu.com/question/20467170/answer/392949674)   **推荐看这个**

[矩阵归一化L2范数matlab代码](https://blog.sciencenet.cn/blog-810210-655011.html)

[标准化和归一化，请勿混为一谈，透彻理解数据变换](https://blog.csdn.net/weixin_36604953/article/details/102652160)